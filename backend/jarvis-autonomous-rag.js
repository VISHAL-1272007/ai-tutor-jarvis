/**
 * JARVIS AUTONOMOUS RAG PIPELINE
 * 
 * Purpose: Persistent, Hallucination-Free Knowledge Retrieval & Ingestion
 * Requirements: Multi-source scraping, Recursive ingestion, Truth verification, Daily self-training.
 */

const axios = require('axios');
const { performance } = require('perf_hooks');
const path = require('path');
require('dotenv').config({ path: path.join(__dirname, '.env') });

class JarvisAutonomousRAG {
    constructor() {
        this.pinecone = require('./pinecone-integration');
        this.serperKey = process.env.SERPER_API_KEY;
        this.groqKey = process.env.GROQ_API_KEY;
        this.jinaReaderUrl = 'https://r.jina.ai/';
        this.chunkSize = 1000;
        this.chunkOverlap = 200;
    }

    /**
     * CHUNKING LOGIC
     * Splits long text into manageable chunks with overlap
     */
    chunkText(text, size = 1000, overlap = 200) {
        const chunks = [];
        let i = 0;
        while (i < text.length) {
            chunks.push(text.substring(i, i + size));
            i += (size - overlap);
        }
        return chunks;
    }

    /**
     * TRUTH VERIFICATION (CROSS-REFERENCING)
     * Compares information from multiple sources to eliminate hallucinations
     */
    async verifyTruth(query, sourcesData) {
        console.log(`[RAG-TRUTH] Cross-referencing ${sourcesData.length} sources...`);
        
        const context = sourcesData.map((s, i) => `SOURCE ${i+1} (${s.url}):\n${s.content.substring(0, 3000)}`).join('\n\n---\n\n');
        
        const prompt = `You are the JARVIS Truth Verifier. 
Analyze the following information from different sources to answer: "${query}".

RULES:
1. Identify common facts supported by at least 2 sources.
2. Flag contradictions as "UNVERIFIED".
3. Eliminate any data that looks like an advertisement or irrelevant fluff.
4. Output a "VERIFIED CONSOLIDATED REPORT" in 3-5 bullet points.

Sources Context:
${context}`;

        try {
            const response = await axios.post('https://api.groq.com/openai/v1/chat/completions', {
                model: 'llama-3.3-70b-versatile',
                messages: [{ role: 'user', content: prompt }],
                temperature: 0
            }, {
                headers: { 'Authorization': `Bearer ${this.groqKey}` }
            });

            return response.data.choices[0].message.content;
        } catch (error) {
            console.error('Truth Verification Error:', error.message);
            return sourcesData[0]?.content.substring(0, 500) || "Unable to verify.";
        }
    }

    /**
     * RECURSIVE DATA INGESTION
     * Fetches deep content, chunks it, and stores in Vector DB
     */
    async ingestDeep(topic) {
        console.log(`ðŸš€ [AUTONOMOUS-RAG] Deep Ingestion for: ${topic}`);
        
        // 1. Get deep links from Serper
        const searchRes = await axios.post('https://google.serper.dev/search', {
            q: `${topic} technical documentation in-depth whitepaper`,
            num: 10
        }, {
            headers: { 'X-API-KEY': this.serperKey }
        });

        const urls = searchRes.data.organic.map(o => o.link);
        const results = [];

        // 2. Parallel Ingestion (Crawl Level 0)
        for (const url of urls.slice(0, 4)) { // Top 4 deep links
            try {
                const response = await axios.get(`${this.jinaReaderUrl}${url}`, { timeout: 15000 });
                const content = response.data;
                
                // Chunk and store
                const chunks = this.chunkText(content);
                const facts = chunks.slice(0, 5).map((c, i) => ({
                    id: `rag-${Date.now()}-${Math.random()}`,
                    text: c,
                    metadata: { topic, source: url, type: 'deep_ingestion' }
                }));

                if (this.pinecone) {
                    await this.pinecone.upsertKnowledge(facts);
                }
                
                results.push({ url, content });
                console.log(`âœ… Ingested and Vectorized: ${url}`);
            } catch (e) {
                console.warn(`Failed to ingest ${url}: ${e.message}`);
            }
        }

        return results;
    }

    /**
     * DAILY SELF-TRAINING WORKER
     * Background task to fetch latest tech news and update memory
     */
    async runDailySelfTraining() {
        console.log('ðŸ“… [RAG-WORKER] Starting Daily Knowledge Update...');
        const techTopics = ['Artificial Intelligence', 'Cybersecurity', 'Space Exploration', 'Quantum Computing'];
        
        for (const topic of techTopics) {
            await this.ingestDeep(`Latest news on ${topic} ${new Date().toISOString().split('T')[0]}`);
        }
        
        console.log('âœ… [RAG-WORKER] Daily training complete.');
    }

    /**
     * THE PERSISTENT ANSWER ENGINE
     * Answers queries by: 1. Vector Search + 2. Web Search + 3. Truth Verification
     */
    async answer(query) {
        const startTime = performance.now();
        console.log(`ðŸ” [JARVIS-RAG] Query: ${query}`);

        // Phase 1: Local Vector Retrieval
        const localMemory = this.pinecone ? await this.pinecone.searchPineconeKnowledge(query, 5) : [];
        
        // Phase 2: Live Multi-Source Fetch
        const liveSources = await this.ingestDeep(query);
        
        // Phase 3: Truth Verification
        const verifiedFacts = await this.verifyTruth(query, liveSources.slice(0, 3));

        // Phase 4: Final Synthesis
        const prompt = `You are JARVIS, an autonomous AI with access to a verified RAG pipeline.
        Answer the following question using the provided Verified Facts and Local Memory.
        
        USER QUESTION: ${query}
        
        VERIFIED FACTS:
        ${verifiedFacts}
        
        LOCAL MEMORY:
        ${localMemory.map(m => m.metadata.text).join('\n---\n')}
        
        INSTRUCTIONS:
        - Be highly specific.
        - Cite sources if available.
        - If unsure, state what is unverified vs verified.
        - Use the memory to avoid generic answers.`;

        const response = await axios.post('https://api.groq.com/openai/v1/chat/completions', {
            model: 'llama-3.3-70b-versatile',
            messages: [{ role: 'user', content: prompt }],
            temperature: 0.1
        }, {
            headers: { 'Authorization': `Bearer ${this.groqKey}` }
        });

        const timeTaken = (performance.now() - startTime).toFixed(0);
        return {
            answer: response.data.choices[0].message.content,
            verificationStatus: 'VERIFIED',
            latency: `${timeTaken}ms`,
            sources: liveSources.map(s => s.url)
        };
    }
}

module.exports = new JarvisAutonomousRAG();
