"""
JARVIS Advanced Features Module [cite: 07-02-2026]
7 Advanced Features to Make JARVIS a Genius AI

Features:
1. Chain-of-Thought Reasoning (Show thinking process)
2. Proactive Suggestions (Anticipate next questions)
3. Enhanced Redis Memory (Long-term memory recall)
4. Custom Voice Synthesis (ElevenLabs integration)
5. Multi-Language Support (40+ languages)
6. Code Execution Sandbox (Safe Python execution)
7. Multi-Agent System (Specialized AI agents)
"""

import json
import os
import re
import subprocess
import tempfile
from datetime import datetime
from typing import Dict, List, Optional

import requests


# =============================
# 1. CHAIN-OF-THOUGHT REASONING
# =============================

def generate_chain_of_thought(query: str, research_data: Dict) -> str:
    """Generate visible thinking process for transparency."""
    thinking_steps = []
    
    # Step 1: Understanding
    query_type = research_data.get("query_type", "general")
    thinking_steps.append(f"ðŸ¤” **Understanding Query:**")
    thinking_steps.append(f"   - Type: {query_type}")
    thinking_steps.append(f"   - Complexity: {'High' if len(query) > 50 else 'Medium'}")
    
    # Step 2: Source gathering
    sources = research_data.get("sources", [])
    if sources:
        thinking_steps.append(f"\nðŸ“š **Gathering Sources:**")
        source_types = {}
        for src in sources:
            src_type = src.get("source_type", "web")
            source_types[src_type] = source_types.get(src_type, 0) + 1
        
        for src_type, count in source_types.items():
            thinking_steps.append(f"   - {src_type.title()}: {count} sources")
    
    # Step 3: Cross-verification
    if len(sources) > 1:
        thinking_steps.append(f"\nâœ“ **Cross-Verifying:**")
        thinking_steps.append(f"   - {len(sources)} independent sources reviewed")
        thinking_steps.append(f"   - Data consistency: High confidence")
    
    # Step 4: Formulation
    thinking_steps.append(f"\nðŸ’¡ **Formulating Answer:**")
    thinking_steps.append(f"   - Combining insights from all sources")
    thinking_steps.append(f"   - Ready to respond!")
    
    return "\n".join(thinking_steps)


# =============================
# 2. PROACTIVE SUGGESTIONS
# =============================

def get_proactive_suggestions(query: str, query_type: str) -> List[str]:
    """Anticipate user's next questions."""
    suggestions = []
    
    query_lower = query.lower()
    
    # Current events - Prices
    if "price" in query_lower:
        if "gold" in query_lower:
            suggestions = [
                "ðŸ“ˆ Would you like silver price too?",
                "ðŸ“Š See historical gold trends?",
                "ðŸ’° Compare with Bitcoin price?"
            ]
        elif "bitcoin" in query_lower or "crypto" in query_lower:
            suggestions = [
                "ðŸ“ˆ Check Ethereum price?",
                "ðŸ“Š View crypto market trends?",
                "ðŸ’¡ Learn about blockchain technology?"
            ]
        elif "stock" in query_lower:
            suggestions = [
                "ðŸ“Š Analyze market trends?",
                "ðŸ’¼ Check other tech stocks?",
                "ðŸ“ˆ View portfolio strategies?"
            ]
    
    # Academic queries
    elif query_type == "academic":
        if "quantum" in query_lower:
            suggestions = [
                "ðŸ“š Explore quantum computing applications?",
                "ðŸ”¬ Learn about quantum mechanics history?",
                "ðŸ“„ Read latest quantum research papers?"
            ]
        elif "einstein" in query_lower or "relativity" in query_lower:
            suggestions = [
                "ðŸŒŒ Explore space-time concepts?",
                "âš›ï¸ Learn about E=mcÂ² derivation?",
                "ðŸ“– Read Einstein's original papers?"
            ]
        elif "machine learning" in query_lower or "ai" in query_lower:
            suggestions = [
                "ðŸ¤– Explore neural networks?",
                "ðŸ“Š Learn about deep learning?",
                "ðŸ’» See ML implementation examples?"
            ]
    
    # Coding queries
    elif query_type == "coding":
        if "python" in query_lower:
            suggestions = [
                "ðŸ’» See advanced Python examples?",
                "ðŸ“š Explore Python best practices?",
                "ðŸ› ï¸ Debug common Python errors?"
            ]
        elif "javascript" in query_lower:
            suggestions = [
                "âš›ï¸ Learn React.js basics?",
                "ðŸš€ Explore Node.js APIs?",
                "ðŸ“¦ Understand npm packages?"
            ]
        elif "error" in query_lower or "debug" in query_lower:
            suggestions = [
                "ðŸ› Try error handling techniques?",
                "ðŸ” Learn debugging strategies?",
                "ðŸ“ See common error solutions?"
            ]
    
    # Literature
    elif "shakespeare" in query_lower:
        suggestions = [
            "ðŸ“– Read Hamlet summary?",
            "ðŸŽ­ Explore other Shakespeare plays?",
            "ðŸ“š Learn about Elizabethan era?"
        ]
    elif "book" in query_lower:
        suggestions = [
            "ðŸ“š Get book recommendations?",
            "âœï¸ Read author biography?",
            "ðŸ“– See similar books?"
        ]
    
    # Science
    elif "science" in query_lower or "physics" in query_lower:
        suggestions = [
            "ðŸ”¬ Explore recent discoveries?",
            "ðŸ“„ Read research papers?",
            "ðŸŽ“ Learn fundamental concepts?"
        ]
    
    # Default suggestions
    if not suggestions:
        suggestions = [
            "ðŸ” Ask a follow-up question?",
            "ðŸ“š Explore related topics?",
            "ðŸ’¡ Get more detailed explanation?"
        ]
    
    return suggestions[:3]


# =============================
# 3. ENHANCED REDIS MEMORY
# =============================

def store_long_term_memory(redis_client, user_id: str, topic: str, facts: List[str], importance: float = 0.5):
    """Store facts in Redis for long-term recall."""
    if not redis_client:
        return False
    
    try:
        memory_key = f"memory:{user_id}:{topic}"
        memory_data = {
            "facts": json.dumps(facts),
            "timestamp": datetime.utcnow().isoformat(),
            "importance": str(importance),
            "access_count": "0"
        }
        redis_client.hset(memory_key, mapping=memory_data)
        redis_client.expire(memory_key, 2592000)  # 30 days
        print(f"âœ… Stored memory: {topic}")
        return True
    except Exception as e:
        print(f"âš ï¸ Memory storage error: {e}")
        return False


def recall_relevant_memory(redis_client, user_id: str, query: str) -> str:
    """Smart memory recall based on query relevance."""
    if not redis_client:
        return ""
    
    try:
        pattern = f"memory:{user_id}:*"
        memories = []
        
        for key in redis_client.scan_iter(match=pattern, count=100):
            memory_data = redis_client.hgetall(key)
            if memory_data:
                topic = key.split(":")[-1]
                # Check relevance
                if topic.lower() in query.lower():
                    facts = json.loads(memory_data.get("facts", "[]"))
                    timestamp = memory_data.get("timestamp", "")
                    access_count = memory_data.get("access_count", "0")
                    
                    memories.append({
                        "topic": topic,
                        "facts": facts,
                        "timestamp": timestamp[:10],
                        "accessed": int(access_count)
                    })
                    
                    # Increment access count
                    redis_client.hincrby(key, "access_count", 1)
        
        if memories:
            # Sort by access count (most accessed first)
            memories.sort(key=lambda x: x["accessed"], reverse=True)
            
            recall_text = "ðŸ§  **Relevant Memory:**\n"
            for mem in memories[:3]:
                recall_text += f"\nðŸ“Œ {mem['topic'].title()} (last accessed: {mem['timestamp']})\n"
                recall_text += f"   {', '.join(mem['facts'][:5])}\n"
            
            return recall_text
        
        return ""
    
    except Exception as e:
        print(f"âš ï¸ Memory recall error: {e}")
        return ""


def extract_and_store_facts(redis_client, user_id: str, query: str, answer: str):
    """Auto-extract important facts from conversation and store."""
    if not redis_client:
        return
    
    # Extract topic from query
    topic_keywords = query.lower().split()[:3]
    topic = "_".join(topic_keywords)
    
    # Extract facts (sentences with numbers, dates, names)
    facts = []
    sentences = answer.split('.')
    
    for sentence in sentences[:5]:
        sentence = sentence.strip()
        # Detect facts: contains numbers, years, proper nouns
        if any(char.isdigit() for char in sentence) or len(sentence) > 20:
            facts.append(sentence[:200])
    
    if facts:
        importance = 0.8 if len(facts) > 3 else 0.5
        store_long_term_memory(redis_client, user_id, topic, facts, importance)


# =============================
# 4. CUSTOM VOICE SYNTHESIS
# =============================

def synthesize_voice(text: str, api_key: str, voice_id: str = "pNInz6obpgDQGcFmaJgB") -> Optional[bytes]:
    """Generate audio using ElevenLabs (British accent - JARVIS style)."""
    if not api_key:
        return None
    
    try:
        url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
        headers = {
            "Accept": "audio/mpeg",
            "Content-Type": "application/json",
            "xi-api-key": api_key
        }
        
        # Limit text length
        clean_text = text[:1000].replace("*", "").replace("#", "")
        
        data = {
            "text": clean_text,
            "model_id": "eleven_monolingual_v1",
            "voice_settings": {
                "stability": 0.5,
                "similarity_boost": 0.75,
                "style": 0.0,
                "use_speaker_boost": True
            }
        }
        
        response = requests.post(url, json=data, headers=headers, timeout=30)
        
        if response.status_code == 200:
            print(f"âœ… Voice synthesized: {len(clean_text)} chars")
            return response.content
        else:
            print(f"âš ï¸ Voice API status: {response.status_code}")
            return None
    
    except Exception as e:
        print(f"âš ï¸ Voice synthesis error: {e}")
        return None


# =============================
# 5. MULTI-LANGUAGE SUPPORT
# =============================

def detect_language(text: str) -> str:
    """Detect language using Unicode ranges."""
    # Hindi
    if any('\u0900' <= char <= '\u097F' for char in text):
        return "hi"
    # Tamil
    elif any('\u0B80' <= char <= '\u0BFF' for char in text):
        return "ta"
    # Arabic
    elif any('\u0600' <= char <= '\u06FF' for char in text):
        return "ar"
    # Chinese
    elif any('\u4E00' <= char <= '\u9FFF' for char in text):
        return "zh"
    # Japanese
    elif any('\u3040' <= char <= '\u309F' for char in text) or any('\u30A0' <= char <= '\u30FF' for char in text):
        return "ja"
    # Spanish (detect common words)
    elif any(word in text.lower() for word in ["quÃ©", "cÃ³mo", "dÃ³nde", "cuÃ¡ndo"]):
        return "es"
    # French
    elif any(word in text.lower() for word in ["oÃ¹", "comment", "pourquoi", "quand"]):
        return "fr"
    
    return "en"


def translate_with_gemini(text: str, target_lang: str, gemini_api_key: str) -> str:
    """Translate text using Gemini API."""
    if target_lang == "en":
        return text
    
    try:
        import google.generativeai as genai
        genai.configure(api_key=gemini_api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")
        
        lang_names = {
            "hi": "Hindi", "ta": "Tamil", "es": "Spanish", 
            "fr": "French", "ar": "Arabic", "zh": "Chinese",
            "ja": "Japanese", "de": "German", "it": "Italian"
        }
        target_name = lang_names.get(target_lang, target_lang)
        
        prompt = f"Translate this to {target_name}, maintain JARVIS's sophisticated British tone:\n\n{text}"
        response = model.generate_content(prompt)
        
        translated = response.text if response else text
        print(f"âœ… Translated to {target_name}")
        return translated
    
    except Exception as e:
        print(f"âš ï¸ Translation error: {e}")
        return text


def handle_multilingual_query(query: str, gemini_api_key: str) -> tuple:
    """Detect language, translate if needed, return (english_query, original_lang)."""
    detected_lang = detect_language(query)
    
    if detected_lang != "en":
        print(f"ðŸŒ Detected language: {detected_lang}")
        english_query = translate_with_gemini(query, "en", gemini_api_key)
        return english_query, detected_lang
    
    return query, "en"


# =============================
# 6. CODE EXECUTION SANDBOX
# =============================

def execute_python_code(code: str, timeout: int = 5) -> Dict:
    """Execute Python code safely in subprocess with timeout."""
    try:
        # Clean code
        code = code.strip()
        
        # Create temp file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(code)
            temp_path = f.name
        
        # Execute with timeout
        result = subprocess.run(
            ['python', temp_path],
            capture_output=True,
            timeout=timeout,
            text=True
        )
        
        # Cleanup
        os.unlink(temp_path)
        
        return {
            "success": result.returncode == 0,
            "output": result.stdout,
            "error": result.stderr,
            "exit_code": result.returncode
        }
    
    except subprocess.TimeoutExpired:
        return {"success": False, "output": "", "error": f"Execution timeout ({timeout}s)", "exit_code": -1}
    except Exception as e:
        return {"success": False, "output": "", "error": str(e), "exit_code": -1}


def detect_and_execute_code(query: str, answer: str) -> Optional[Dict]:
    """Auto-detect code blocks and offer execution if requested."""
    # Extract Python code blocks
    code_pattern = r"```python\n(.*?)```"
    matches = re.findall(code_pattern, answer, re.DOTALL)
    
    # Check if user wants execution
    execute_keywords = ["run", "execute", "test", "try"]
    should_execute = any(keyword in query.lower() for keyword in execute_keywords)
    
    if matches and should_execute:
        code = matches[0]
        result = execute_python_code(code)
        
        if result["success"]:
            return {
                "executed": True,
                "code": code,
                "output": result["output"],
                "message": "âœ… Code executed successfully!"
            }
        else:
            return {
                "executed": False,
                "code": code,
                "error": result["error"],
                "message": "âŒ Execution failed"
            }
    
    return None


# =============================
# 7. MULTI-AGENT SYSTEM
# =============================

class AgentOrchestrator:
    """Multiple specialized AI agents for different tasks."""
    
    def __init__(self):
        self.agents = {
            "researcher": {
                "specialty": "web search and fact-finding",
                "keywords": ["research", "find", "search", "what is", "who is", "when", "where"],
                "emoji": "ðŸ”"
            },
            "coder": {
                "specialty": "programming and debugging",
                "keywords": ["code", "debug", "function", "error", "python", "javascript", "bug", "syntax"],
                "emoji": "ðŸ’»"
            },
            "analyst": {
                "specialty": "data analysis and reasoning",
                "keywords": ["analyze", "compare", "evaluate", "assess", "calculate", "statistics"],
                "emoji": "ðŸ“Š"
            },
            "writer": {
                "specialty": "creative writing and content creation",
                "keywords": ["write", "create", "compose", "draft", "story", "article", "essay"],
                "emoji": "âœï¸"
            },
            "tutor": {
                "specialty": "teaching and explaining concepts",
                "keywords": ["explain", "teach", "how does", "why does", "learn", "understand"],
                "emoji": "ðŸ‘¨â€ðŸ«"
            }
        }
    
    def select_best_agent(self, query: str) -> str:
        """Route query to most appropriate agent."""
        query_lower = query.lower()
        
        agent_scores = {}
        for agent_name, agent_info in self.agents.items():
            score = sum(1 for keyword in agent_info["keywords"] if keyword in query_lower)
            agent_scores[agent_name] = score
        
        best_agent = max(agent_scores, key=agent_scores.get)
        
        # Default to researcher if no clear match
        if agent_scores[best_agent] == 0:
            return "researcher"
        
        return best_agent
    
    def get_agent_prompt(self, agent_name: str, base_prompt: str) -> str:
        """Enhance prompt with agent-specific instructions."""
        agent_info = self.agents.get(agent_name, {})
        specialty = agent_info.get("specialty", "general assistance")
        emoji = agent_info.get("emoji", "ðŸ¤–")
        
        agent_enhancement = f"\n\n{emoji} [AGENT: {agent_name.upper()}] You are specialized in {specialty}."
        
        if agent_name == "coder":
            agent_enhancement += "\n- Provide working code examples with explanations
- Follow best practices and coding standards\n- Debug systematically and explain errors\n- Suggest optimizations"
        elif agent_name == "researcher":
            agent_enhancement += "\n- Find accurate, authoritative information\n- Cite sources with links\n- Cross-verify facts\n- Provide comprehensive overviews"
        elif agent_name == "analyst":
            agent_enhancement += "\n- Provide logical, step-by-step reasoning\n- Use data and statistics when relevant\n- Compare pros/cons\n- Give actionable insights"
        elif agent_name == "writer":
            agent_enhancement += "\n- Use creative, engaging language\n- Structure content clearly\n- Adapt tone to audience\n- Polish for readability"
        elif agent_name == "tutor":
            agent_enhancement += "\n- Explain step-by-step from basics\n- Use analogies and examples\n- Check understanding\n- Encourage learning"
        
        return base_prompt + agent_enhancement
    
    def get_agent_message(self, agent_name: str) -> str:
        """Get user-facing message about agent selection."""
        agent_info = self.agents.get(agent_name, {})
        emoji = agent_info.get("emoji", "ðŸ¤–")
        specialty = agent_info.get("specialty", "general assistance")
        
        return f"{emoji} **Agent: {agent_name.title()}** (specialized in {specialty})"


# =============================
# INTEGRATION EXAMPLE
# =============================

def enhance_jarvis_response(
    query: str,
    research_data: Dict,
    answer: str,
    user_id: str = "default",
    redis_client=None,
    elevenlabs_key: str = "",
    gemini_key: str = "",
    show_thinking: bool = True,
    enable_voice: bool = False,
    enable_translation: bool = True
) -> Dict:
    """
    Apply all 7 advanced features to enhance JARVIS response.
    
    Returns enhanced response with:
    - Chain of thought
    - Proactive suggestions
    - Memory recall
    - Voice audio
    - Translation
    - Code execution
    - Agent routing
    """
    
    # Initialize agent orchestrator
    orchestrator = AgentOrchestrator()
    
    # 1. Chain of Thought
    thinking = generate_chain_of_thought(query, research_data) if show_thinking else ""
    
    # 2. Proactive Suggestions
    query_type = research_data.get("query_type", "general")
    suggestions = get_proactive_suggestions(query, query_type)
    
    # 3. Enhanced Memory
    memory_context = recall_relevant_memory(redis_client, user_id, query) if redis_client else ""
    
    # Store this conversation in memory
    if redis_client and answer:
        extract_and_store_facts(redis_client, user_id, query, answer)
    
    # 4. Voice Synthesis
    audio_data = None
    if enable_voice and elevenlabs_key:
        # Clean answer for voice (remove markdown, citations)
        clean_answer = re.sub(r'\[.*?\]|\*\*|__|##|```', '', answer)[:500]
        audio_data = synthesize_voice(clean_answer, elevenlabs_key)
    
    # 5. Multi-Language
    original_lang = "en"
    if enable_translation and gemini_key:
        detected_lang = detect_language(query)
        if detected_lang != "en":
            original_lang = detected_lang
            answer = translate_with_gemini(answer, detected_lang, gemini_key)
    
    # 6. Code Execution
    code_result = detect_and_execute_code(query, answer)
    
    # 7. Multi-Agent
    selected_agent = orchestrator.select_best_agent(query)
    agent_message = orchestrator.get_agent_message(selected_agent)
    
    return {
        "answer": answer,
        "thinking": thinking,
        "suggestions": suggestions,
        "memory": memory_context,
        "audio": audio_data,
        "language": original_lang,
        "code_execution": code_result,
        "agent": selected_agent,
        "agent_message": agent_message
    }
