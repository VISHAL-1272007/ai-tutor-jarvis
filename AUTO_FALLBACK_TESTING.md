# ðŸ§ª AUTO-FALLBACK SYSTEM - TESTING GUIDE

**Status**: âœ… **LIVE & READY TO TEST**
**Date**: January 21, 2026
**Endpoint**: `POST /omniscient/auto-fallback`

---

## ðŸš€ Quick Start Testing

### Test 1: Simple Query (Should use Groq)
```bash
curl -X POST http://localhost:3000/omniscient/auto-fallback \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is Python?"
  }'
```

**Expected**: Groq responds with ~80+ confidence, stops early âœ…

---

### Test 2: Complex Query (Should fallback to Claude)
```bash
curl -X POST http://localhost:3000/omniscient/auto-fallback \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Explain quantum entanglement and its implications for cryptography",
    "domain": "science",
    "minConfidence": 75
  }'
```

**Expected**: Groq tries (~60%), falls back to Claude (~85+%) âœ…

---

### Test 3: Math Problem (High confidence required)
```bash
curl -X POST http://localhost:3000/omniscient/auto-fallback \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Integrate: âˆ«(3xÂ² + 2x + 1)dx",
    "domain": "math",
    "minConfidence": 80
  }'
```

**Expected**: May try multiple models, returns confident answer âœ…

---

### Test 4: Production URL
```bash
curl -X POST https://ai-tutor-jarvis.onrender.com/omniscient/auto-fallback \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is machine learning?",
    "minConfidence": 50
  }'
```

**Expected**: Response from production backend âœ…

---

## ðŸ“Š Testing Checklist

- [ ] **Groq alone** - Returns fast (<500ms)
- [ ] **Fallback triggered** - Tests Claude availability
- [ ] **All APIs fail** - Returns proper error
- [ ] **Low confidence** - Shows warning
- [ ] **High confidence** - Stops early
- [ ] **Context parameter** - Affects response
- [ ] **Domain parameter** - Routes correctly
- [ ] **Rate limiting** - Respects limits
- [ ] **Error handling** - Graceful failures
- [ ] **Response format** - All fields present

---

## ðŸ” What to Look For in Response

### Success Response
```json
{
  "success": true,
  "data": {
    "answer": "...",           â† Main answer
    "model": "groq",           â† Which API responded
    "confidence": 87,          â† Confidence % (0-100)
    "minConfidenceRequired": 50, â† Your threshold
    "allAttempts": [...],      â† All tries
    "warning": null            â† No issues
  }
}
```

### Fallback Evidence
```
allAttempts: [
  { "model": "groq", "confidence": 62 },        â† Low confidence
  { "model": "claude", "confidence": 88 }       â† Fell back, better!
]
```

### Low Confidence Warning
```
"warning": "Low confidence (45%). Consider asking for clarification."
```

---

## â±ï¸ Performance Testing

### Expected Times
| Scenario | Time | Status |
|----------|------|--------|
| Groq confident | 300-500ms | âœ… |
| 1 fallback | 2-3s | âœ… |
| 2 fallbacks | 4-5s | âœ… |
| 3 fallbacks | 6-8s | âš ï¸ |

---

## ðŸ› Debugging

### Check logs for:
```
ðŸ”„ Trying GROQ...
âœ… GROQ confidence: 78%
ðŸŽ¯ High confidence from GROQ, stopping search
```

### Or for fallback:
```
ðŸ”„ Trying GROQ...
âœ… GROQ confidence: 45%
ðŸ”„ Trying CLAUDE...
âœ… CLAUDE confidence: 85%
ðŸŽ¯ High confidence from CLAUDE, stopping search
```

---

## ðŸŽ¯ Test Cases by Query Type

### Coding Questions
```json
{
  "question": "Write a Python function to sort an array",
  "domain": "code",
  "minConfidence": 70
}
```
*Expect: High confidence from Groq (coding specialty)*

---

### Math Questions
```json
{
  "question": "What is the derivative of xÂ²?",
  "domain": "math",
  "minConfidence": 80
}
```
*Expect: Fallback to Claude for better math precision*

---

### Science Questions
```json
{
  "question": "How does photosynthesis work?",
  "domain": "science",
  "minConfidence": 75
}
```
*Expect: Mix of APIs, good final answer*

---

### General Knowledge
```json
{
  "question": "What is AI?",
  "domain": "general",
  "minConfidence": 50
}
```
*Expect: Quick Groq response, high confidence*

---

## ðŸ”§ Testing from Code

### JavaScript
```javascript
async function testAutoFallback() {
  const response = await fetch('http://localhost:3000/omniscient/auto-fallback', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      question: 'What is machine learning?',
      minConfidence: 60
    })
  });
  
  const data = await response.json();
  
  console.log('âœ… Success:', data.success);
  console.log('ðŸ“ Answer:', data.data.answer);
  console.log('ðŸ¤– Model:', data.data.model);
  console.log('ðŸ“Š Confidence:', data.data.confidence + '%');
  console.log('ðŸ”„ Attempts:', data.data.allAttempts);
}

testAutoFallback();
```

---

### Python
```python
import requests
import json

response = requests.post(
    'http://localhost:3000/omniscient/auto-fallback',
    json={
        'question': 'What is machine learning?',
        'minConfidence': 60
    }
)

data = response.json()
print(f"âœ… Success: {data['success']}")
print(f"ðŸ“ Answer: {data['data']['answer']}")
print(f"ðŸ¤– Model: {data['data']['model']}")
print(f"ðŸ“Š Confidence: {data['data']['confidence']}%")
print(f"ðŸ”„ Attempts: {data['data']['allAttempts']}")
```

---

## ðŸ“ˆ Monitoring During Testing

### Watch for:
- âœ… Response times decrease with confidence
- âœ… Fallbacks trigger at appropriate confidence thresholds
- âœ… All APIs tried in correct order (Groq â†’ Claude â†’ OpenRouter â†’ HuggingFace)
- âœ… Rate limiting works (max 100 req/15min)
- âœ… No duplicate API calls
- âœ… Proper error handling on failures

---

## ðŸŽ“ Real-World Test Scenarios

### Scenario 1: Support Bot
```
Customer: "How do I reset my password?"
â†’ Query: "How do I reset my password?"
â†’ Expected: High confidence from Groq, instant response
â†’ Result: Fast, accurate answer âœ…
```

### Scenario 2: Homework Help
```
Student: "Explain photosynthesis in detail"
â†’ Query with minConfidence: 75
â†’ Expected: Might fallback to Claude for depth
â†’ Result: High-quality educational answer âœ…
```

### Scenario 3: Technical Question
```
Developer: "What's the time complexity of quicksort?"
â†’ Query with domain: "code"
â†’ Expected: Groq answers quickly and accurately
â†’ Result: <500ms response, high confidence âœ…
```

### Scenario 4: Ambiguous Question
```
User: "Tell me about Python"
â†’ Query: Generic question
â†’ Expected: Groq tries, might fall back if low confidence
â†’ Result: Clear, confident answer âœ…
```

---

## âœ… Success Criteria

- [ ] Response received < 2s average
- [ ] Confidence scores reasonable (20-95 range)
- [ ] Fallbacks only when confidence < 65%
- [ ] All attempts tracked in response
- [ ] No errors in production logs
- [ ] Proper error handling for failed APIs
- [ ] Rate limiting enforcement working
- [ ] All fields present in response
- [ ] Warning shown for low confidence
- [ ] Multiple test queries show variety in models used

---

## ðŸš¨ Troubleshooting

### "All APIs failed to respond"
- Check all API keys in .env
- Verify network connectivity
- Check API quotas/rate limits
- Review Render logs

### "Confidence always low"
- Verify API keys are valid
- Check if APIs are properly returning responses
- Review scoring algorithm thresholds
- Test individual APIs

### "Always uses same model"
- Check if other APIs are configured
- Verify confidence thresholds triggering fallback
- Review response quality from first API
- Check API availability

### Timeout issues
- Verify Render instance has enough resources
- Check if requests are hitting rate limits
- Verify backend startup is complete
- Monitor response times in production

---

## ðŸ“ Test Report Template

```
Date: January 21, 2026
Tester: [Your Name]
Environment: [Local/Production]

## Test Results

### Test 1: Simple Query
- Query: "What is Python?"
- Time: ___ ms
- Model: ___
- Confidence: ___%
- Status: âœ… âŒ

### Test 2: Complex Query
- Query: "Explain quantum mechanics..."
- Time: ___ ms
- Model: ___
- Fallbacks: ___
- Status: âœ… âŒ

### Test 3: High Confidence Required
- Query: [Your query]
- Time: ___ ms
- Final Model: ___
- Confidence: ___%
- Status: âœ… âŒ

## Overall Status
- Performance: âš¡ âš¡âš¡ âš¡âš¡âš¡
- Reliability: â­ â­â­ â­â­â­ â­â­â­â­ â­â­â­â­â­
- Ready for Production: âœ… âŒ

Notes: [Your notes]
```

---

## ðŸŽ‰ After Testing

1. **Report results** to the team
2. **Document any issues** found
3. **Note response times** for benchmarking
4. **Verify error handling** works as expected
5. **Check monitoring** captures events properly
6. **Prepare deployment** to production
7. **Set up alerts** for low confidence responses

---

**Ready to Test?** ðŸš€

Start with Test 1, then progress through the scenarios!
